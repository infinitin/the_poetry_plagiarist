\def\baselinestretch{1}
\chapter{Poem Analysis}
\ifpdf
    \graphicspath{{Theory/TheoryFigs/PNG/}{Theory/TheoryFigs/PDF/}{Theory/TheoryFigs/}}
\else
    \graphicspath{{Theory/TheoryFigs/EPS/}{Theory/TheoryFigs/}}
\fi

\def\baselinestretch{1.66}

The first phase of implementation is to write a suite of algorithms to analyse a single poem in terms of all the features mentioned in section \ref{sec:features}. The aim is to analyse a large collection of poems in such depth to learn the usage patterns of poetic features for that collection of poems. This is in line with the ultimate aim of avoiding hard-coded rules for different types of poems.

The algorithms will cover the detection of the use of:
\begin{itemize}
\setlength{\itemsep}{0pt}
\item{Rhyme and internal rhyme}
\item{Rhythm, including meter and syllable count}
\item{Alliteration, assonance, consonance, onomatopoeia and other sound devices}
\item{Structure, tense, point of view and repetition}
\end{itemize}

Other algorithms will attempt understand the context of the poem to extract:
\begin{itemize}
\setlength{\itemsep}{0pt}
\item{Characters}
\item{Objects}
\item{Locations}
\item{Descriptions}
\item{Relationships}
\item{Actions}
\item{Symbolism including metaphors, similes and personification}
\end{itemize}

The output of this phase is a full analysis of a single poem. In lieu of this, we will walk through the implementations of each of these algorithms using the poems in Figures \ref{fig:cat} and \ref{fig:limerick} as case studies.


\begin{figure}
\centering
\begin{minipage}{0.45\textwidth}
\centering
\textit{
There once was a big brown cat\\
That liked to eat a lot of mice\\
He got all round and fat\\
Because they tasted so nice
}
\caption{A rhyming quatrain often used in teaching poetry}
\label{fig:cat}
\end{minipage}\hfill
\begin{minipage}{0.45\textwidth}
\centering
\textit{
The limerick packs laughs anatomical\\
Into space that is quite economical.\\
    But the good ones I've seen,\\
    So seldom are clean,\\
And the clean ones so seldom are comical.
}
\caption{A limerick about limericks}
\label{fig:limerick}
\end{minipage}
\end{figure}


\section{Obtaining Phonetic Structure}

When poets choose words they take the sound of the words when spoken out loud into account as well as their (literal or symbolic) meaning. As explained in section \ref{sec:words}, we can use CMU Pronounciation Dictionary (CMUPD) to get around the difficulty of determining phonetic structure by spelling. A word in the CMUPD is mapped to a list of different pronunciations for the same word. Each pronunciation is a list of phonemes that make up that particular pronunciation of that word, including indication of emphasis on the syllables as explained in section \ref{sec:words}.

We want to convert the poems into their phoneme lists for use by the detection algorithms. This needs to be done word by word, so we first need to \textit{tokenise} the sentence. Tokenisation involves splitting each sentence into a list of its basic components; words and punctuation. Once we have done that, we can simply iterate through the list and run each word through the CMUPD. Some words have multiple pronunciations, so we consider each possible permutation of pronouncing each line of the poem. Each of the pronunciations of the first line of Figure \ref{fig:cat} is shown in Figure \ref{fig:catpronun}.

\begin{figure}
\centering
{[{['DH', 'EH1', 'R']}]} \\
{[{['W', 'AH1', 'N', 'S']}]}\\
{[{['W', 'AA1', 'Z']}, {['W', 'AH1', 'Z']}, {['W', 'AH0', 'Z']}, {['W', 'AO1', 'Z']}]}\\
{[{['AH0']}, {['EY1']}]}\\
{[{['B', 'IH1', 'G']}]}\\
{[{['B', 'R', 'AW1', 'N']}]}\\
{[{['K', 'AE1', 'T']}]}
\caption{The different ways of pronouncing the first line of the cat poem}
\label{fig:catpronun}
\end{figure}

Unfortunately, the CMU Pronunciation Dictionary only has about 133,000 words. This means that occasionally we will fail to translate to the phonetic structure, particularly in Shakespearean poems. We get around this by temporarily converting the word into its closest match that exists in the dictionary and returning the phonetic structure in its place.

Python difflib provides a function to find the closest matches of a word to a list of words, based on the Ratcliff/Obershelp pattern recognition algorithm. The complexity of this algorithm is quadratic in the average case and cubic in the worst case. However, difflib's implementation avoids this using a 'junk' heuristic and hashing so the worst case becomes quadratic and the best case linear. The behaviour is based on  how many sequences have in common. Since we are only dealing with single words at a time, we have a higher chance of the best case. On average it takes X MILLISECONDS to look up a 4-letter word and Y MILLISECONDS to look up an 8-letter word, which is easily fast enough given that speed is not a priority for this phase since it is a pre-processing phase, not a time-sensitive one.

We could use a variety of other techniques to get around this problem other than string matching:
\begin{itemize}
\item{Break many syllable words into likely part-words, e.g. 'thrift' and 'less' instead of 'thriftless'}
\item{Try all combinations of stress and syllables}
\item{Train a finite-state transducer model as in \cite{dobrivsek2010towards}}
\end{itemize}

The first option only works in a limited number of situations that are reasonably handled by the string matching solution. For example, 'thriftless' would become 'shiftless', which has an identical phonetic structure. The second option can result in poor performance and more false negatives or false positives than would be worth the added processing.

The final option is the most viable and would be used if the generation phase depended on perfect readings of the poems, as the stochastic n-gram methodology of RKCP would. However, as we only use this as an approximation for abstraction in later phases, we can afford to use a more naive implementation.


\section{Rhyme}

We want to detect end-line and internal rhyme, as described in section \ref{sec:rhyme}. Along with detecting it, we want to be able to build a normalised rhyme scheme representation for easy analysis in the abstraction phase. 

First we collect the phoneme set of the words that we wish to analyse for rhyme. For end-line, we collect the last word of each line of the poem. For internal rhyme, we collect the all the words in a particular stanza.

Once we have our list, we can run it through Algorithm BLAH.

1 for each word in the list:
2 	for each pronuciation of the word:
3		for each phoneme in the pronunciation:
4			if this phoneme is stressed:
5				get all the rhyme phoneme pattern from this phoneme onwards in this pronunciation
6				if we have seen this pattern before: 
7					assign it corresponding rhyme token
8				else:
9					map this pattern to a new rhyme token
10				
11				append this token to a set of possible tokens for this word				
12	append the set possible tokens for this word to the unzipped rhyme scheme
13 build all possible permutations of rhyme scheme from they unzipped rhyme scheme
14 normalise the rhyme schemes
	
There are a few tricks to this algorithm, namely obtaining the rhyme phoneme pattern on line 5 and the process of building and normalising the rhyme scheme in lines 11 to 14.

\subsection{Obtaining the Rhyme Phoneme Pattern}

Two words rhyme when:
\begin{itemize}
\item{the last phoneme of each word match}
\item{the vowel sounds after and including the first stressed syllable match \textbf{in order}}
\end{itemize}

The algorithm finds the first stressed syllable in line 4. At that point we only need to iterate through the rest of the pronunciation and find the vowel sounds and the last phoneme check that the last phonemes. Putting them together in order gives the unique rhyme phoneme pattern. 

For example strategy and tragedy, kite and height - colourful diagrams!			

\subsection{Building and Normalising the Rhyme Scheme}

Each unique rhyme phoneme pattern is represented by a single capital letter starting with 'A'. This is matches with the standard convention for rhyme schemes used in theory. 

The complication comes in the various ways of pronouncing a single word. Therefore, we create a list for every possible rhyme pattern for a each word. The list of these lists is what the algorithm refers to as the 'unzipped' rhyme scheme on line 12 and 13. Figure BLAH shows the unzipped rhyme scheme for the limerick in Figure BLAH. Not that the word 'anatomical' has two pronunciations that affect the rhyme pattern, according to the CMUPD.

FIGURE OF THE UNZIPPED RHYME SCHEME

We then build every possible permutation of this list, which then gives us a list of the possible rhyme schemes for these given words. We leave this list as it is and do not make a claim for any rhyme scheme to be more likely than any other at this stage.

\section{Rhythm}

We attempt to recognise all three types of rhythm described in \ref{sec:rhythm}. 

\subsection{Detecting Syllabic Rhythm}

The number of syllables in a word is equal to the number of vowel phonemes it has. We know that all vowel phonemes have a stress marker appended to it so we can just count the number of stress markers in the word.

However, Syllabic Rhythm is done on a line-by-line basis. Therefore we tokenise each line and aggregate the vowel phonemes across all words in the line to get the number of syllables for that line.

If we take one permutation of the line in Figure \ref{fig:catpronun}, we can see that each word has one vowel phoneme, so each word in that sentence is monosyllabic. Therefore the number of syllables in the line is 7.

The full syllabic rhythm for the poems in Figure \ref{fig:cat} and \ref{fig:limerick} are 7-8-6-7 and 11-6-5-11-11 respectively. We represent these as a list of integers. We create a separate list for each stanza.

\subsection{Detecting Quantitative and Accentual Rhythm}

While theory counts rhythm in terms of metre and feet, as described in \ref{sec:rhythm}, some poems might have rhythm without following one of these pre-defined popular styles. Instead of searching for them, we will extract the pattern of stressed and unstressed syllables for each line without making a claim on how it matches to theory yet.

We choose to do this mainly because there could be multiple possibilities for the stress pattern of a line due to variations in emphasis for particular words, e.g. '\textbf{ob}ject' and 'ob\textbf{ject}'. The variability of possible stress patterns is compounded by some limitations of the CMUPD:
\begin{itemize}
\item{Some words are restricted to a single stress pattern even though it does not lose or change the meaning of the word if it was emphasised differently. For example, '\textbf{quan}tity', 'quan\textbf{ti}ty' and 'quanti\textbf{ty}' are all valid, but the CMUPD only recognises the first because the other two are unusual in normal speech (but not for poetry).}
\item{Similarly, the CMUPD fixes monosyllabic words to one of stressed or unstressed as in Figure \ref{fig:catpronun}. However, they can be either so we need to allow for both possibilities.}
\item{Stresses on some words have changed over time. For example \textbf{prov}ed was pronounced prov\textbf{ed} in Shakespeare's era}
\item{Though not necessarily a limitation, we do not give importance to light or secondary stress in a word (the '2' stress marker). We therefore assume it could be either '1' or '0'.}
\item{Poetic license often allows words to be pronounced with an entire extra syllable. For example \textit{de-served} could be pronounced as \textit{de-ser-ved}.}
\end{itemize}

We account for these by increasing the number of possible readings. However, this will lead to a lot of possibilities. For example the line in Figure \ref{fig:catpronun} will give us any combination of '1's and '0's since they are all monosyllabic and by the second point above we want to allow for either. 

We narrow this down initially by taking away any occurrences of the same stress three or more times in a row in the same line, because no one will ever read a poem in this way.  Like with rhyme, we do not make a claim for any stress pattern to be more likely than any other at this stage.


\section{Sound Devices}

We aim to detect each of the sound devices described in \ref{sec:sound}.

\subsection{Detecting Consecutive Sounds}

RETHINK THIS IMPLEMENTATION

For assonance, consonance and alliteration, we only care about whether or not they are being used, not necessarily which sounds are repeated or where in the poem it occurs.

\subsection{Onomatopoeia}

Some onomatopoeia are recognised in traditional dictionaries, while some are not. There are also many variations of the same sound, e.g. 'Aah' versus 'Aaah'. New onomatopoeia can be created at any point depending on the sound the writer wants to portray. This range of variation and lack of consistency makes it difficult to detect all occurrences of onomatopoeia.

However, we can use the WrittenSound.com dictionary of onomatopoeia to recognise the most common ones. We can check each word in the poem for existence in the dictionary or for a very similar words to those in the dictionary. To do this we can use the Levenshtein distance, a measure of the number of changes required to turn one string into another. If the Levenshtien distance between a word and an entry in the dictionary is less than or equal to 1, not including extensions to the head or tail of the onomatopoeia, then we consider it to be onomatopoeic.

Furthermore, WrittenSound has mappings between the onomatopoeia and the type of sound they represent. For example, \textit{'ding'} represents a 'hard hit', probably of a 'metal' object. This can be useful somehow.


\section{Form and Structure}

We implement some basic detectors for the form and structure of the poem. This does not include analysis of words and phrases themselves as that will be done in the abstraction phase, as described in section BLAH.

The algorithms for detecting the features of structure described in section \ref{sec:structure} are fairly simple:

\begin{itemize}
\item{\textbf{Number of stanzas} = Number of blank lines + 1}
\item{\textbf{Number of lines per stanza} = Number of new line characters per stanza}
\item{\textbf{Number of repeated lines} = Length of the list of lines - Size of the set of lines (sets only hold unique elements)}
\item{\textbf{Number of distinct sentences} = The number of sentences returned when parsed using the CLiPS \textit{parsetree} function. More lines than sentences indicates enjambment.}
\end{itemize}

The poem in Figure \ref{fig:cat} has one stanza, four lines, no repeated lines and two distinct sentences, indicating enjambment.

We can also determine the point of view of the speaker, i.e. whether it is in first or third person. We look for the word 'I' anywhere in the poem and as long as it is outside speech marks, we say that the entire poem is in first person. Otherwise we default to third person. Figure \ref{fig:cat} is written in third person but Figure \ref{fig:limerick} is in first person.

The tense of each line can be found by analysing the verb in that sentence. CLiPS pattern library provides a very easy method of doing this using their 'tenses' algorithm. It also gives us the \textit{aspect}, e.g. perfect, progressive. However, tests found this to be less accurate so we will settle for just the tense for this stage.

We record the tense of each line as well as the overall tense of the poem. EXAMPLES

\section{Context and Pragmatics}
Here we describe the approach to the difficult challenge of determining the context of the poem in terms of its characters and their relations, descriptions etc. as described in section \ref{sec:pragpers}. The aim is to build a representation of the characters much like a human reader would in their mind. This will then be compared in the abstraction section to find a correlation between these structures and types of poetry.

\subsection{ConceptNet Relations}
ConceptNet is a semantic network of '\textit{general knowledge}'. Each node in the network is a natural language word or phrase called a \textit{concept}. Edges in the network represent a relationship between two concepts. These relationships come in various types including, but not limited to:

\begin{description}
\item[MadeOf] \hfill \\ What is it made of? \hfill \\ E.g. tree - MadeOf $\rightarrow$ wood
\item[IsA] \hfill \\ What kind of thing is it? \hfill \\ E.g. banana - IsA $\rightarrow$ fruit
\item[AtLocation] \hfill \\ Where would you find it? \hfill \\ E.g. priest - AtLocation $\rightarrow$ church
\item[CapableOf] \hfill \\ What can it do? \hfill \\ bird - CapableOf $\rightarrow$ sing
\item[Desires] \hfill \\ What does it want? \hfill \\ banker - Desires $\rightarrow$ his loan to be repay
\item[HasA] \hfill \\ What does it have in its possession? \hfill \\ old person - HasA $\rightarrow$ white hair
\item[HasProperty] \hfill \\ What properties does it have? \hfill \\ doctor - HasProperty $\rightarrow$ smart
\item[PartOf] \hfill \\ What is it part of? \hfill \\ player - PartOf $\rightarrow$ team
\item[ReceivesAction] \hfill \\What can you do to it? \hfill \\ book - ReceivesAction $\rightarrow$ read
\item[CreatedBy] \hfill \\ How do you bring it into existence? \hfill \\ sound - CreatedBy $\rightarrow$ vibration
\item[UsedFor] \hfill \\ What do you use it for? \hfill \\ guitar - UsedFor $\rightarrow$ make music
\item[MotivatedByGoal] \hfill \\ Why would you do it? \hfill \\ learn - MotivatedByGoal $\rightarrow$ knowledge
\end{description}

Each of these relationships also has its inverse, e.g. NotIsA. We can use these relationships to build a cohesive story about particular characters during the generation phase as well as a few of our own:

\begin{description}
\item[Believes] \hfill \\ What does the character perceive to be true? \hfill \\ Little Red Riding Hood - Believes $\rightarrow$ Wolf is her grandma
\item[SendMessage] \hfill \\ What did the character say or write?  \hfill \\ Little Red Riding Hood - SendMessage $\rightarrow$ What a big mouth you have
\item[ReceiveMessage] \hfill \\ What did the character hear or read?  \hfill \\ Little Red Riding Hood - ReceiveMessage $\rightarrow$ The better to eat you with!
\item[TakesAction] \hfill \\ What did the character do?  \hfill \\ Wolf - TakesAction $\rightarrow$ Swallow Little Red Riding Hood
\item[Named] \hfill \\ What is the name of the character? \hfill \\ Gotham Vigilante - Named $\rightarrow$ Batman
\end{description}

We also have the corresponding inverses for these relations. 

In keeping with the theme of this paper we cannot simply hard-code or randomise the choice of relations in building a poem. Therefore, we need to be able to analyse these relationships in existing poems during the abstraction phase to find correlations. For example, we may find that descriptive poems have a high number of \textit{HasProperty} relations and very few characters.  

To do this, we need to be able to extract relationships between concepts in a particular poem in lieu of ConceptNet relations. For example:

**Give the cat example**

\subsection{Semantic Labelling using Noah's ARK}

It would be very difficult to determine these relationships from a syntactical parse alone. This is due to the complex nature of the English language, in particular verb usage. For example, the phrase \textit{tasted so nice} is a description rather than an action because the word \textit{tasted} in this case is being used as a linking verb, where it is usually an action verb.

These complexities are further compounded by the fact that we cannot rely on correct grammar in poems. We therefore need a \textit{semantic} parse. Noah's ARK is an informal research group run by Noah Smith at Carnegie Mellon University. They provide online API access to two tools for linguistic structure analysis, \textit{SEMAFOR} and \textit{TurboParser}. Both of these tools in conjunction are satisfactory for our aim to extract ConceptNet relations from natural language.

\subsubsection{FrameNet Semantic Role Labelling using SEMAFOR}
\label{sec:sema}

Semantic Role Labelling (SRL) is best described with an example. Take the sentence \textit{"The shopkeeper told the hoodlum to go away"}, we wish to recognise the verb \textit{'to tell'} as the target, \textit{'the shopkeeper'} as the speaker, \textit{'go away'} as the message and \textit{'the hoodlum'} as the addressee. This can be seen clearly in Figure BLAH. 

This is independent of the syntactic structure of the sentence and does require grammatical correctness. The SRL for the \textit{'Yoda-speak'} equivalent will remain the same, as shown in Figure BLAH.

These labels are retrieved through the SEMAFOR tool, which was trained on FrameNet data to determine the frame-semantic structure of the text. FrameNet is a lexical database of \textit{semantic frames}, which describe the meaning of a word based on the words that typically participate with it, known as frame elements. It is based on the Frame Semantics Theory, introduced by Charles J.Fillmore et al.

We can use these to derive the ConceptNet relations by looking for the occurrence of frames, and elements thereof, that correspond to the ConceptNet relation. The manually chosen list of the ConceptNet relations with the frames and corresponding elements that translate directly into that relation is given in the APPENDIX.

However, each list may not be exhaustive for its corresponding ConceptNet relation and there are some relations that will not be picked up by this method.


\subsubsection{Semantic Dependency Relations using TurboParser}
\label{sec:turbo}

The Stanford Dependencies is another representation based around the relationships between words. All dependency relations are strictly binary and come in various types depending on the participants (called the \textit{governor} and the \textit{dependent}).

The semantic dependency tree for the previous shopkeeper example can be seen in Figure BLAH.

This representation fills the gaps left by the frame-semantic parse using the following heuristics:

PSEUDO-CODE HEURISTICS HERE

Together, these tools provide a fairly complete coverage of the ConceptNet relations.


\subsection{Extracting and Binding Relations to Characters}

At this point, the derived ConceptNet relations are only a set of abstracted FrameNet frames and matched dependencies. This alone does not give us much more information than if we were to use the frame-semantic parse on its own. The true usefulness of this approach only arises if the relations can be bound to characters of the poem. For the shopkeeper example, we would recognise \textit{the shopkeeper} and \textit{the hoodlum} as objects with SendMessage and ReceiveMessage relations bound to each of them respectively with respect to the \textit{go away} message.

We can represent the desired output as a set of 'hubs', with each character at the centre of the hub as in Figure BLAH. This will also improve our knowledge for the generation phase in that we will know the \textit{number} of characters typical for a poem type, the \textit{number and type} of relations associated with \textit{each} character, as well as allow us to find commonalities in the types of characters themselves.

To reach the desired representation, we execute Algorithm BLAH:

1 for each sentence in the poem:
2   get the dependency relations and frame semantic parse
3	collapse loose leaves of the dependency relations
4	find and create possible characters
5	find candidate ConceptNet relations from the frame-semantic parse
6	for each character:
7		get all associated dependency relations
8		for each associated dependency relation:
9			if the dependent is involved in a candidate relation from the frame-semantic parse:
10				bind the relation to the current character and continue
11			else:
12				use the heuristics for dependency relations to find possible ConceptNet relations
13				bind any that are found to the current character and continue
				
Here we describe each step in detail.

\subsubsection{Obtaining the Semantic Dependency Relations and Frame-Semantic Parse from Noah's ARK}

Noah's ARK provides parse data from both SEMAFOR and TurboParser in a JSON format that can be accessed by sending a request to their demo API. However, there is a cap of 20 seconds processing time for any request so we only send one sentence at a time to be safe. Some basic experimentation has shown that this does not hinder accuracy.

SEMAFOR returns the Frame-Semantic parse in JSON format, an example of which can be seen in Figure BLAH. We leave it in this format because we only need to access this data once when finding the candidate relations on line 5 of Algorithm BLAH.

TurboParser returns the Semantic Dependency Parse in CoNLL data format, whose structure can be seen in Table \ref{tab:CoNLL}. An example of the output can be seen in Figure BLAH.

\begin{table}
\centering
    \begin{tabular}{|l|l|l|}
    \hline
    Field Number & Field Name & Description                                                \\ \hline
    1            & ID         & Token counter, starting at 1 for each new sentence.        \\
    2            & FORM       & Word text form or punctuation symbol                       \\
    3            & LEMMA      & Lemma or stem of FORM                                      \\
    4            & CPOSTAG    & Coarse-grained part-of-speech tag                          \\
    5            & POSTAG     & Fine-grained part-of-speech tag                            \\
    6            & FEATS      & Unordered set of syntactic and/or morphological features   \\
    7            & HEAD       & ID of the parent of the current token ('0' if root)        \\
    8            & DEPREL     & Dependency relation to the HEAD                            \\
    9            & PHEAD      & Projective head of current token                           \\
    10           & PDEPREL    & Dependency relation to the PHEAD                           \\ \hline
    \end{tabular}
\caption{The CoNLL data format output by TurboParser.}
\label{tab:CoNLL}
\end{table}

We parse this into a simple dependencies dictionary format shown in Table \ref{tab:DepDict} for easy access and processing downstream.

\begin{table}
\centering
    \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    ID & FORM   & CPOSTAG & POSTAG & HEAD & DEPREL \\ \hline
    1  & There  & EX      & EX     & 3    & expl   \\
    2  & once   & RB      & RB     & 3    & advmod \\
    3  & was    & VB      & VBD    & 0    & null   \\
    4  & a      & DT      & DT     & 7    & det    \\
    5  & big    & JJ      & JJ     & 7    & amod   \\
    6  & brown  & JJ      & JJ     & 7    & amod   \\
    7  & cat    & NN      & NN     & 3    & nsubj  \\
    8  & who    & WP      & WP     & 9    & nsubj  \\
    9  & liked. & VB      & VBD    & 7    & rcmod  \\
    10 & to     & TO      & TO     & 11   & aux    \\
    11 & eat    & VB      & VB     & 9    & xcomp  \\
    12 & a      & DT      & DT     & 13   & det    \\
    13 & lot    & NN      & NN     & 11   & dobj   \\
    14 & of     & IN      & IN     & 13   & prep   \\
    15 & mice   & NN      & NNS    & 14   & pobj   \\
    16 & .      & .       & .      & 3    & punct  \\ \hline
    \end{tabular}
\caption{The dependencies dictionary data structure for the first sentence of the cat poem.}
\label{tab:DepDict}
\end{table}

TurboParser and SEMAFOR are resource heavy (SEMAFOR requires minimum 8GB RAM), so it makes sense to run it on a server. Since the output from Noah's ARK is exactly what we want and the request is fairly quick (typically BLAH milliseconds for simple sentences, BLAH milliseconds for complex ones) and speed is not a priority for this project, there is no need to run our own copy on our own server.

\subsubsection{Collapsing Loose Leaves of the Semantic Dependency Relations}
\label{sec:collapse}

In a lot of cases, the character or relation that we look for is a phrase, not just a word. For example in Figure BLAH the character should be \textit{a lot of mice} rather than just \textit{mice}. In fact if we skipped this step, we would get two characters; \textit{a lot} and \textit{mice}, which is obviously wrong.

Another example is the phrase \textit{tasted so nice}. If we did not collapse the tree, we would have that \textit{they} took the action of \textit{tasted} and can be described as \textit{nice}, both of which are wrong again.

The non-demo version of TurboParser provides different styles of dependency representation. This includes collapsed dependencies but not exactly in the way we want it done. First, we manually select the dependencies that we want to collapse (APPENDIX).

By default, the parent of the dependency keeps all its attributes unchanged except for merging its form with that of the leaf, e.g. \textit{of} and \textit{mice} becomes \textit{of mice}. However, there are some cases where we wish to retain the part-of-speech (POS) tag of the leaf and overwrite the parent's part of speech tag. For example, \textit{of mice} should retain the 'NNS' POS tag of \textit{mice} rather than keep the 'PRP' POS tag of \textit{of}. The full list of these conditions are in the APPENDIX.

\begin{itemize}
\item{If the leaf is an adjective, the parent is a verb and the dependency relation is \textit{'dep'} then we retain the adjective POS. These conditions usually imply a \textit{linking verb} generally used to describe a property, not an action. E.g. 'tasted so nice' is an adjectival phrase despite the use of a verb.}
\item{The \textit{'acomp'} dependency relation is also evidence of a linking verb.}
\item{The \textit{'pobj'} and \textit{'prep'} dependency relations are evidence of the preposition example described above. }
\end{itemize}

Then we follow Algorithm 2:
1 Get a list of all the leaves in the graph.
2 For each leaf in the reverse of this list:
3	If the dependency relation of this leaf (i.e. from its parent) is collapsable:
4		Get the parent
5		Merge the form of the parent and the leaf
6		If necessary, the parent retains the part-of-speech tag of the leaf
7		The leaf is destroyed and the parent becomes the leaf.
8		Loop back to line 3.

Figure BLAH shows a dry run of this algorithm on the sentence \textit{"There once was a big brown cat who liked to eat a lot of mice."}

\subsubsection{Finding and Creating Characters}
\label{sec:characters} 

A naive method for finding characters would be to look for nouns and pronouns to recognise characters in a poem. This would actually be sufficient, but we can do better. Notice in the poem in Figure BLAH, the cat character is represented by the words \textit{'a cat'} and \textit{'he'}. Similarly, \textit{'a lot of mice'} and \textit{'they'} represent the same character.

In Computational Linguistics, this problem is called \textbf{Anaphora Resolution}. It is an ongoing research area and I will present a new potential solution in section \ref{sec:ar}.

Part of the solution is gathering some basic semantic information about the character. We would like to determine whether the character:

\begin{enumerate}
\item{is plural or singular.}
\item{is male, female, neutral or unknown.}
\item{the character is an animate/living object, an inanimate physical object or a non-object.}
\end{enumerate}

The first point is easiest:
\begin{itemize}
\item{If it is a noun and the part-of-speech tag ends in an 'S', it is plural.}
\item{If it is a pronoun, check for membership in the manually built list of plural pronouns (e.g. 'they', 'them').}
\end{itemize}

The pronoun case for the second point is similar; we check for membership in the manually built list of male pronouns (e.g. 'he', 'him') and the separate list of female pronouns (e.g. 'she', 'her'). 

The noun case is trickier. First we need to find the \textit{synset} of the noun. Synsets are sets of cognitive synonyms, e.g. \textit{car} and \textit{automobile} are in the same synset, but not \textit{cable car}. Once we have this, we can use the hypernym relationships between synsets.

A hypernym of a synset is a \textbf{type-of} relation. For example, the synset \textit{mammal} is a hypernym of \textit{cat} because cat is a type of mammal. Similarly, \textit{animal} is also a hypernym of cat, as well as being a hypernym of mammal. The full hypernym tree for \textit{cat} can be seen in Figure BLAH. 

The \textit{direct hypernym} of a synset is the synset directly above it in the hypernym tree; \textit{feline} in the case of the cat. The \textit{inherited hypernym} of a word refers to any word that appears in its hypernym tree. WordNet, a lexical database of the cognitive relations between words provides all of these resources.

Now, finally, we can check for whether a noun is male or female by looking for the existence of particular synsets that imply a gender. For example, the \textit{'female'} synset would be an inherited hypernym of the synset \textit{'cow'}. Therefore we know that cows are female. Similarly, \textit{'maharaja'} has the hypernym \textit{'prince'}, which we know to be male.

We can extend this practice to the final point of determining the animation of the character by checking if the \textit{'living thing'} and \textit{'physical object'} synset is an inherited hypernym of the synset of the noun concerned.


\subsubsection{Extracting Candidate ConceptNet Relations from the Frame-Semantic Parse}
\label{sec:candidate}

As mentioned in section \ref{sec:sema}, we have a manually built map between FrameNet frames and ConceptNet relations. Given this, we can carry out Algorithm BLAH.

1 for each frame found in the frame-semantic parse:
2	look up the target of the frame in the map
3	if it can help build a ConceptNet relation:	
4		retrieve the frame elements
5		replace the frame elements with the corresponding text from the poem
6			if we cannot find all the elements we are looking for, we leave it blank
7		add mapping from the text of the frame target to the newly built relation
	
Let us take the shopkeeper example from earlier. If it exists, we then look for the specific frame elements that will allow us to build the ConceptNet relation.

GO THROUGH THE SHOPKEEPER EXAMPLE

\subsubsection{Obtaining the Associated Dependency Relations for a Particular Character}

This step breaks up the semantic dependency tree and flatten it into the character-centric hubs as shown in Figure BLAH.

First, we want to identify the character in the dependency tree. All of the relations going out from it are naturally related dependencies of the character, so they get added to the list, see Figure BLAH.

The single relation coming into this character is also a related dependency, so we added that to the hub and reverse the direction of the branch, see Figure BLAH.

Now we have a tree with the character as the root. The next step is to flatten it so that everything is related to the character. We do this by recursively converting all the grandchildren of the character root node to a direct child node until there are no more grandchildren. This process is illustrated in Figure BLAH.

We repeat this process for each character starting from the leftmost character in the sentence. However, we quickly notice that there will be duplication; the same dependency will be associated to more than one character. To avoid this, we can prune these hubs by working backwards through the list of characters (i.e. starting from the rightmost in the sentence) and removing duplications in earlier nodes, as shown in Figure BLAH. 

This works because the head of the last character will be lower down in the tree than the head of any other character. This has the effect of removing the duplicated dependencies such that the last one standing is only associated to the one it was closest to in the original tree.


\subsubsection{Binding ConceptNet Relations to Characters}
	
Now that we have our hub data structure for all characters, we now need to look at each branch and of each hub and decide if it can be converted into a ConceptNet relation.

First, we check if the text of the child maps to one of the candidate relations we extracted from the frame-semantic parse in section \ref{sec:candidate}. If it does, then we accept that and move on to the next child without checking the dependency relation since it is likely to be the more accurate. Sometimes the dependant of the relation will be blank because we could not find the right frame element as explained earlier. In this case, we just assume that this is a relation to the next character in the characters list. This is a fair assumption given the limited number of characters per sentence, the general forward reference structure of sentences and the fact that most of the relations we look to build are between characters.

If there is no candidate relation for this child, we then look at the type of the dependency between it and the character. We use the heuristics described in section \ref{sec:turbo} to convert it into a ConceptNet relation.

If we cannot find a relation through either of the above methods then it is likely there isn't one, so we remove it from the hub.

In all of those steps, we need to look out for negative adverbs such as 'not', 'seldom', 'rarely' etc. which we use to negate the ConceptNet relation found. We also need to look out for antonyms in the target word in the frame-semantic parse. For example, the \textit{Experiencer-focus} frame helps us find \textit{Desires} and \textit{NotDesires} ConceptNet relations depending on whether the target word is synonymous with 'love' or with 'hate', for example.

We can see this final step being applied to our ongoing example in Figure BLAH.


\subsection{Anaphora Resolution}
\label{sec:ar}
We can now clearly see the anaphora problem as described in section \ref{sec:characters}. We must match up the \textit{'a cat'} character and \textit{'he'} character, and the \textit{'they'} character with the \textit{'a lot of mice'} character. 

In this particular example, we can simply match the plurals and singulars together. However, we may not always be so lucky. We may also run into a situation where the cat could be referred to as \textit{'the feline'} instead of \textit{'he'}.

Section \ref{sec:arback} gives an overview of the state of the art solutions. Our solution is also pretty darn simple at the moment, so I am going to wait to see if I can do some of the more complicated things and then write this section up.


\subsection{Peeks at Future Development of Pragmatic Language Analysis}

If I get time...


\section{Symbolism and Imagery}

This particular poetic technique can be very subtle and difficult to detect. Of the ones listed in section \ref{sec:symbol}, we are able to recognise the use of two; similes and personification.

\subsection{Personification}

We used the animation state of characters for anaphora resolution. We can take this idea further to detect the use of personification in poetry.

The following relations are symptomatic of a sentient being:

\begin{itemize}
\item{'Named' and 'NotNamed'}
\item{'Desires' and 'NotDesires'}
\item{'Believes' and 'NotBelieves'}
\item{'SendMessage' and 'NotSendMessage'}
\item{'ReceiveMessage' and 'NotReceiveMessage'}
\end{itemize}

Therefore, if a character that is marked as an inanimate physical object has any of these relations, it is likely that the author of the poem was using personification to give the object human-like behaviour.

We can also take advantage of the \textit{Semantic Type} attribute of FrameNet elements. FrameNet marks frame elements with a semantic precondition if they are to be of a certain type, for example only \textit{'Sentient'} semantic types can be the \textit{'Abuser'} and the \textit{Victim} in the \textit{'Abusing'} frame. By looking up these semantic types in FrameNet as we are building the ConceptNet relations, we are able to flag characters as evidence for personification.

\subsection{Simile}

Similes are relatively easy to detect because they often use the phrases 'like a' or 'as a' and 'than'. They also follow certain syntactical patterns in that it is usually a noun followed by a verb or adjective, then one of the aforementioned phrases, followed by a noun or an adjective.

A particular symptom of simile use is that the aforementioned phrases will be involved in a prepositional noun phrase, or 'PNP Chunks' to use the parser terminology.

We could take this further by using ConceptNet btw. As fast as a cheetah + cheetah HasProperty fast -> simile.

\subsection{Metaphor}

We need to do something here. Can't just leave it...

%%% ----------------------------------------------------------------------

% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
