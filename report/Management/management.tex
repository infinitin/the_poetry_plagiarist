\chapter{Poetry Generation}
\ifpdf
    \graphicspath{{Management/ManagementFigs/PNG/}{Management/ManagementFigs/PDF/}{Management/ManagementFigs/}}
\else
    \graphicspath{{Management/ManagementFigs/EPS/}{Management/ManagementFigs/}}
\fi

The final stage of development entails generating new, novel and creative poetry by utilising the information gathered in the previous analysis and interpretation sections.

\section{Approach}
Most previous attempts at automatic poetry generation, including ones mentioned in Section \ref{sec:related_work}, prioritise adherence to poetic features and structure above all else. This is done with the justification that:
\begin{itemize}
\item{poetry rarely follows syntactical rules of English grammar.}
\item{readers of poems, as humans, are extremely apt at finding subtle meaning in language, even if it was not intended by the author.}
\end{itemize}

However, grammatical rules in poetry are broken for some poetic purpose like matching a rhyme scheme or rhythm pattern. They are therefore broken with precision and intention, not arbitrarily or randomly.

Furthermore, we discussed in Section \ref{sec:semantics} that even grammatically correct sentences can be completely nonsensical. We require understanding of the semantic relationships between words to be able to write with intention and in a way that can be understood by the reader.

As discussed in Section \ref{sec:purpose}, the purpose of poetry is to deliver a specific, intentional message. This cannot be done without control over language both syntactically and semantically.

On a separate note, this implementation should be able to produce any type of poem accurately to the information gathered in the analysis and interpretation. We cannot make any assumptions on the length of the lines, the existence of rhyme or the topics covered by the poems.

Therefore, our approach will be \textbf{content first}. We aim to produce poetry that follow syntax and semantics as far as possible and only make specific exceptions for the sake of poetic features.


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
\section{Generating Simple Sentences}
We attempted to recognise the existence of ConceptNet-style relations during the analysis phase. Our interpretation of the results generalises the use of these relations, so it is natural that we use them to guide generation. For example if we intend to write a poem describing a woman named Mary who wants a monkey, we would start with the persona relation hubs in Figure BLAH below.

1-Named->Mary
1-IsA->woman
1-TA->chase
2-IsA->monkey
2-RA->chase

These relations outline the context of the poem. In lieu with our \textit{content first} approach, we begin by directly translating these relations into syntactically correct natural language \textit{clauses}, which can be organised into lines in a poem. We make use of two tools to do this; \textbf{SimpleNLG}[REF] and \textbf{FrameNet}[REF].

\subsection{SimpleNLG}
SimpleNLG is a Java library that provides useful functionality for natural language generation using the ideas of Reiter and Dale described in Section \ref{sec:bg-nlg}. In particular, it enables us to build \textit{phrases} for nouns, verbs, prepositions, adjectives and adverbs that can be enriched with grammatical metadata such as tense, aspect and perspective (for verbs), as well as plurality, gender and animation for nouns.

These phrases can then be put together into \textit{clauses} that define the roles of each phrase in the desired sentence, for example by specifying the subject and object noun phrases. It then \textit{realises} a grammatically correct natural language sentence taking all of the provided information into account.

We choose to use SimpleNLG because, as its name suggests, it is very simple to use. It provides an almost bespoke interface into the features of the sentence that we picked out in the analysis stage, allowing us to apply the results directly to our new poems. Despite it being a Java library we are able to execute it and access its objects from Python via JPype[REF], a tool for running Java libraries accessing the Java Virtual Machine from Python.

\subsection{FrameNet}

As described in Section \ref{sec:semantics}, we can use FrameNet to \textit{constrain} the building of clauses around individual words. We used it when deriving relations with SEMAFOR in Section BLAH by checking for the existence of certain frames. Now we reverse the process; use selected frames that correspond to particular relations to guide the type and roles of phrases during generation.

Take the Desire relation for example. The frame in FrameNet that would correspond to this is the Desiring frame, which has a list of words, referred to as \textit{lexical units} or \textit{LUs} - that are used in statements that indicate desire, e.g. want, lust, yearn etc. Each of these LUs come with their own \textit{lexical entries}, which describe the frame elements and importantly \textit{Valence patterns}. These define the types of phrases that can be built around a particular LU.

Take the \textit{yearn} LU. It's Valence Patterns are shown in Table BLAH:

Table: https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu6599.xml?mode=lexentry

They are grouped by the permutation of frame elements, e.g. Event+Experiencer vs Experiencer+Focal\_participant. Each group comes with one or more Valence Patterns that indicate the type of phrase (NP means noun phrase, VP means verb phrase etc.), as well as the role in the clause - Ext (Subject), Obj (Object) and Dep (Dependency or Indirect Object).

\subsection{Translating Relations into Clauses}

The general translation process can be seen in Figure/Algorithm BLAH.

Figure:relation -> Get corresponding Frame -> Look up LU -> Select a Valence Pattern -> Order Phrases - > Fill in Gaps

Suppose we take the first relation in Figure BLAH above. We have a character whose ID is 1 and has the name 'Mary'. The corresponding frame for the 'Named' relation is \textit{Referring\_by\_name}. 

However, it is not quite a perfect match because we want a verbs only, whereas this frame includes LUs of other parts of speech as well. Each LU gives indication of its part-of-speech (POS) so we can filter by that. 

Another complication is that the verb 'to name' does not exist in the FrameNet lexicon at all. The closest match is the adjective 'named' found in the \textit{Being\_named} frame. So we need to be able to look up this LU manually as well.

Yet another issue is that not all of these LUs come with full and accurate Valence patterns. FrameNet is an ongoing project with more data being added continuously, but we do not want to use a word that does not have an accurate set of Valence patterns. Thankfully, the status of every LU is provided, so we only look up those that have the \textit{Finished\_Initial} annotation.

It is important to note that all relation translations may have their own set of similar caveats that are to be considered on a case by case basis to improve the quality of lines generated.

Back to our example, after all filtering we are left with two LUs: \textit{call.v} and \textit{named.a} where the string after the full stop in the LU indicates the word POS. We choose one randomly with equal weights. We use \textit{call.v} for this example.

Figure: https://framenet2.icsi.berkeley.edu/fnReports/data/lu/lu11210.xml?mode=lexentry

This LU has three groups of Valence patterns, as can been seen in Figure BLAH. Each group of patterns has an \textit{TOTAL} count, indicating the occurrence frequency of this pattern in their annotated corpus. We assume that these are representative for our purpose and choose the group with the highest total occurrences.

Each pattern within a group also includes an occurrence count. However, the phrases produced by the system would be predictable and mundane if we always choose the most popular again. Instead we select randomly, weighted for occurrence scores. Let our selected Valence pattern be the third one from the top in Figure BLAH.

We then order the phrases according to how they would appear in a sentence using Algorithm Blah.

[Algorithm BLAH for sorting]

The Valence pattern does not include the LU itself so we add as a verb phrase immediately after the subject.

Finally we fill in the gaps by adding carefully selected words to each phrase. We discuss word selection in Sections \ref{sec:common-sense}, \ref{sec:persona} and \ref{sec:new-lines}.

%While the TakesAction and ReceivesAction phrases enable the system to use any verb in its lexicon, having specific builder algorithms for as many relations as possible will greatly increase the quality and variation of the systems language capabilities.


%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section{Semantic Network of Common Sense}
\label{sec:common-sense}
We talked about the idea of modelling the mind as a search space by connecting related \textit{concepts} together in a network in Section BLAHINTHEBG. We gathered inspiration from ConceptNet and discussed Tom De Smedt's attempt to model creativity with such a construct in Sections BLAHINTHEBG and BLAHINTHEBG.

We aim to replicate such a construct bespoke to our purposes, outlined in this section.

\subsection{The Network}
The primary purpose of our network is to help us build clauses out of one or two words. For this, we require our semantic network to give indications of \textbf{actions} that nouns take and receive, as well as properties they have.

The secondary purpose of the network is to provide associative data so to maintain a cohesive topic flow through the poem, rather than jumping between a variety of topics. 

\subsubsection{Nodes}
As with previous attempts, the nodes of the network are the concepts represented by words. However, we enrich these nodes with the POS of the word so to disambiguate between different meanings (e.g. \textit{bear} the noun and \textit{bear} the verb).

\subsubsection{Edges}
The edges of the network indicate the relationship between concepts. The edges are directed and any that can be reversed are done so manually when they are added to the graph. The types of edges are:
\begin{description}
\item[HasProperty] \hfill \\ Stereotypical descriptions of the head of the relation. \hfill \\ doctor.n - HasProperty $\rightarrow$ smart.a \hfill \\ run.v - HasProperty $\rightarrow$ quickly.adv
\item[IsA] \hfill \\ Taxonomy of the head of the relation (Hypernymy). \hfill \\ E.g. banana.n - IsA $\rightarrow$ fruit.n
\item[PartOf] \hfill \\ The head of the relation typically a constituent or member of the tail.  \hfill \\ finger.n - PartOf $\rightarrow$ hand.n
\item[TakesAction] \hfill \\The head of the relation typically performs the action in the tail. \hfill \\ lion.n - TakesAction $\rightarrow$ roar.v
\item[ReceivesAction] \hfill \\The head of the relation typically has the action in the tail done unto it. \hfill \\ book.n - ReceivesAction $\rightarrow$ read.v
\item[RelatedTo] \hfill \\ General, non-specific, reversible association \hfill \\ fat.a - ReceivesAction - eat.v \hfill \\ eat.v - ReceivesAction - pizza.n
\end{description}

All edges are of equal weight. However, there is potential for prioritising certain types of relations or between concepts. For example, we could weight scientific words higher than regular ones to make the program lean towards a more advanced vocabulary.


\subsubsection{Concept Halos and Fields}

The Concept Halo and Field work in the same way as described in Section BLAHINTHEBG. We use them to fill in the gaps in the sentence with intelligent word selection. For example, if we are given a verb, we can lookup the Concept Field for that verb looking only at TakesAction and ReceivesAction edges to find possible subjects and objects for the verb respectfully. Similarly, we can find modifiers for verbs and nouns by looking up HasProperty edges their respective Concept Halos.

\subsection{Sources}
There are various sources for semantic relationships between words. Some are more applicable to our use case given the nature of relations that we desire and the quality of the source.

There are many sources that we have not used only due to the scope of this project. We discuss them in Section BLAHINTHEEVAL.

\subsubsection{Collocations}
The Oxford Collocations Dictionary[ref] is a high-quality source of word combinations. For any given word, it provides the set of words and POS commonly occur in relation to it.

The dictionary entry for \textit{custard} can be seen in Figure BLAH. It gives common adjectives that are used to describe custard, which can clearly be converted into HasProperty Relations. It also shows that custard receives the action of being made, poured and strained, while it takes the actions of thickening and setting. Further, it is closely related to powder and pie.

We can extract relations directly by parsing this dictionary, which is freely available online in compressed HTML format. As the dictionary is developed by Oxford and is used by students of English, its entries are very high quality and dependable.

\subsubsection{Associations}
The University of South Florida Free Associated Norms[ref] provides associations collected directly from human participants. It is used by the Department of Psychology, and is therefore another high quality source of associated words that can be depended on for quality as it was collected in a scientifically sound manner.

The POS of each word is provided but no direction in the association can be determined. Therefore, we may be able to assume that a noun has the property of an associated adjective and that an adjective is a property of associated nouns. However, we cannot assume the whether a noun takes or receives the action of an associated verb. Therefore we use the more general 'RelatedTo' relationship instead.

\subsubsection{NodeBox Perception}
The NodeBox Perception model includes the data used in De Smedt's attempt to model common sense as a network, as discussed in Section BLAHINTHEBG. There is plenty of overlap in the types of semantic relations used in Perception as we will be using for this project, including 'is-a' (IsA), 'is-property-of' (reversed HasProperty), 'is-part-of' (PartOf) and 'is-related-to' (RelatedTo). We generalise all other relations to our \textit{RelatedTo} relation.

This data was manually entered into the system and continues to be used for research, which means that it is a high-quality source of data.

\subsubsection{WordNet}
WordNet is a widely used, high quality lexical database that provides data on hypernymy (IsA relations) and meronymy (PartOf relations). However, since WordNet is very large and already has fast and simple interfaces from Python, we do not merge it with our Knowledge graph at this point. While it may prove useful to consolidate all data in a single graph in the future, it is not necessary at this stage as we can still benefit fully from its data.


\subsubsection{Google Search Suggestions}
Tony Veale's attempt at modelling metaphors[ref] introduced a clever use of Google's search suggestions as a method of tapping in to endings of a sentence. While we currently do not preprocess relations in the way he did to produce Metaphor Magnet, we do use a similar method to help complete sentences, particularly those with indirect objects. 

For example, we would be able to produce a sentence like 'Mary hit the nail with' but be unable to complete the sentence due to a lack of information of indirect objects. However, Google suggestions auto-complete 'hit the nail with' with 'hammer' as one might expect. 

This is the least dependable source of information that we use, so we only use it for that specific case and do not add any to our knowledge network.


\subsection{Concept Similarity}


\subsubsection{Associative Similarity}
Associative similarity between concepts is represented by the length of the shortest past between them in our network. We use Dijkstra's Algorithm[ref] as the basis of finding the shortest path.

Associative similarity helps us choose the best replacement word from a list of candidates. This is very useful when rephrasing to match rhyme and rhythm and will be explained in greater detail in Section \ref{sec:rephrase}. 

It can also help us choose applicable words to start new lines of poetry that stay within context of words used in surrounding lines. This is explained in Section \ref{sec:inc-growth}.

In both of these cases, we are finding the \textit{most} similar concept from a list of candidates of unknown length. This can quickly increase both space and memory complexity without any pruning. We therefore alter Dijkstra's Algorithm to have a limited depth. This way, if we know the shortest path to one of the candidates is $x$, we can abort any further searches that go beyond length $x$ for the shortest path.


\subsubsection{Symbolic Similarity}
Symbolic similarity can be attained through inductive reasoning and substitution by concepts that have a very similar concept halo and field up to a certain depth. Simply put, we can find similarity with the 'Duck Test'; if it looks like a duck, swims like a duck and quacks like a duck, it probably is a duck. Object-oriented programmers can relate this idea to the Liskov substitution principle[ref].

Symbolic similarity has many use cases, including the new method of anaphora resolution proposed in Section BLAHINANALYSIS of the Analysis phase. For this phase, it enables us to implement the following poetic features:
\begin{description}
\item[Similes] \hfill \\ We can describe a property or an action of a persona in our poem by comparing the persona to an concept in our knowledge network that (stereotypically) has that property or takes/receives that action. \hfill \\ The relation \textit{1-TA$\rightarrow$run quickly} can be built into the phrase 'runs like a cheetah' by recognising that cheetahs are stereotypically quick runners.
\item[Metaphors] \hfill \\ Similarly to Similes, we can find concepts in our network that share a number of semantic relations with the persona we are trying to describe. \hfill \\ Any persona with relations \textit{1-TakesAction$\rightarrow$crawl}, \textit{1-HasProperty$\rightarrow$social}, \textit{1-HasProperty$\rightarrow$small} is analogous to an insect because it's concept in the graph shares those relations.
\item[Personification] \hfill \\ If we are given an inanimate object as a persona, we can describe it as if it were sentient by looking giving it relations that belong to a sentient being. \hfill \\ A car could be personified by giving it all the relations that a lion has in our concept network, to produce sentences like \textit{'The car roared'}.
\item[Irony] \hfill \\ Our knowledge network is made up of semantic attributes that are expected for each concept. Irony can be attained by producing lines of poetry that describe a concept doing the opposite of the concepts given in our graph.
\end{description} 

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section{Persona Creation and Management}
\label{sec:persona}
\subsection{Referencing Specific Persona}
When we convert the relation \textit{1-Named$\rightarrow$Mary} in Figure BLAH to a phrase, we need to refer to the persona using IsA relations. So when we build the clause with the verb 'named' and object 'Mary', we will look up the persona that this relation was taken from and find an IsA relation. In this example, we will find woman, and when we add the determiner 'a', we get the clause \textit{'a woman named Mary'}.

Now when we convert the \textit{1-TA$\rightarrow$chase} relation, we follow a similar process of finding a way to reference character 1, with the inclusion of the name of the persona (if available) as another candidate for the reference. This will give us either \textit{'The woman chases'} or \textit{'Mary chases'}.

\subsection{Adding New Persona}
Now since the verb 'chase' is \textit{transitive}, i.e. it requires a subject \textbf{and} an object, we need a persona that receives the action 'chase'. If we look through the relations of the other known persona, we will find the relation \textit{2-RA$\rightarrow$chase} and we use \textit{2-IsA$\rightarrow$monkey} to derive the corresponding reference to that character. So we can complete the sentence by adding \textit{'monkey'} to the end, giving us either \textit{'The woman chases a monkey'} or \textit{'Mary chases a monkey'}.

Suppose we could not find a corresponding ReceivesAction relation for 'chase' in any of the current persona. We must then find a concept in our knowledge network that receives the action 'chase'. We do this by looking at the concept field of the \textit{'chase.v'} concept in our knowledge graph for only the edges with type ReceivesAction. This gives us the required list of concepts from which to select the object of the clause. We use concept similarity to find the most applicable object given the current context of the poem; a process to be described in detail in Section \ref{sec:new-lines}, but for now let's assume that we use the concept \textit{'thief.n'}.

When we add a new noun to the poem, we need to create a new persona object for it so that we can refer back to it later. The new character is instantiated with an IsA relation to its noun word, i.e. \textit{thief}. Its plurality, gender and animation are all derived from the word itself using the process described in Section BLAHINTHEANALYSIS.

\subsection{Anaphora and Presupposition}
So far we are only able to refer to persona by Named or IsA relations that are already part of the persona's relations. This leads to to combinations of clauses such as \textit{'A woman named Mary. Mary chased the monkey.'}, which is completely \textit{un}natural language.

The natural way to phrase it would be \textit{'A woman named Mary. She chased the monkey.'}. In this case, the introduction of the pronoun 'she' is a contextual reference back to the aforementioned persona. We discussed the resolution of such anaphora in Section BLAHINTHEANALYSIS.

Another option for variety in reference is to use \textit{presuppositions}; implicit assumptions about context. This can give us clause combinations such as \textit{'A woman named Mary. She chased the monkey. The animal stole her banana'}. Here we refer back to the monkey persona by looking for a hypernyms in WordNet and IsA relations in our knowledge network for the concept \textit{'monkey.n'}. The implicit assumption made is that monkeys are animals, so the reader would understand the reference.

A more advanced method of presupposition introduction would be to look at stereotypical recipients (concept field) of the concept \textit{'chase.v'} in our knowledge network. This may give us the clause combination \textit{'A woman named Mary. She chased the monkey. The thief stole her banana'}. In this case, we are making an implicit assumption that the monkey is a thief because, according to our knowledge network, thieves stereotypically get chased. This assumption gets added to the context and can be used to develop the story, a process described in Section \ref{sec:inc-growth}.

\subsection{Semantic Types}
Suppose we had the relations \textit{2-RA$\rightarrow$chase} and \textit{2-IsA$\rightarrow$monkey} but with no corresponding TakesAction relation in any other known persona. We would need either need to create a new persona to be the subject of the clause or we would choose an already existing persona to be the subject.

In the former case we can simply look up our knowledge network in the same way we did when finding the object of the sentence. However, if we run across this case often (which we might, see Section \ref{sec:new-lines}), we could end up introducing a new persona every line which can lead to a much less cohesive poem. So we would like to use the latter case and look at reusing persona that we already know about.

There's a trap here though. What if the only other persona we knew of was an inanimate object like a plate? Or a non-object like evolution? To say \textit{'A plate chases the monkey'} or \textit{'Evolution chases the monkey'} makes no sense. Unless we are using personification, we would want a sentient being to be the subject of the 'chase' action.

Thankfully, FrameNet provides \textit{semantic types} with every frame element of a frame. This indicates the required animation of any noun in all Valence patterns of the LU. We also store the animation of every persona in the system upon creation, so we can refer to this when deciding if a persona is a relevant match with a particular semantic type. If no existing persona are applicable, we can revert back to finding one from our knowledge network.

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section{Poem Initialisation}

Before we start building any poem, we need to construct the basic structure for the desired form of poetry. We also want to be able to take some \textit{inspiration} to initialise the content that can either be sampled from the knowledge network or from the user.

\subsection{Overall Structure}
Our new poem first needs to be initialised with values of features that span across the entire poem, namely:
\begin{itemize}
\item{Number of stanzas}
\item{Number of lines per stanza}
\item{Number and locations of repeated lines}
\item{Tense}
\item{Perspective}
\item{Rhyme Scheme}
\end{itemize}

All of these can be retrieved directly from the template developed in the previous chapter. The template is made up of probability distributions for the various values a feature can take on, so by default we get the value by sampling this distribution. 

However, if one result is clearly more probably than the rest, we want to treat it as unambiguous. For example, more than half of the rhyme schemes found for limericks were AABBA, as pictured in figure \ref{fig:rhyme-scheme-chart}. Each of the other values are some slight variation on AABBA (e.g. AABCA, ABCCB etc.) and occur less than a ninth of the time at maximum.

To generalise this, we take the rule that if the any feature has a single value in its probability distribution that occurs more than half of the time and the next highest value is less than a third of that value, we treat it as unambiguous and \textit{always} apply it to the initial structure of this type of poem.


\subsection{Inspiration}
The poetry generation process can be seeded \textit{inspiration}, which can be in the form of words or relations. Inspiration can come from the user, or the program can come up with it itself. Inspiration from the user is input manually into the system.

When the program derives its own inspiration, it looks to the common hypernym ancestors of previous poems found in section BLAHINTHEINTERPRETATION. It chooses a random hypernym and recursively looks for all holonyms in WordNet recursively, out of which one will be randomly selected. A persona is then created and used as the single source of inspiration for the rest of the poem. Section \ref{sec:apply-inspr} explains how.
 

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section{Incremental Growth}
\label{sec:inc-growth}

\subsection{Applying Inspiration}
\label{sec:apply-inspr}

\subsection{Creating New Lines}
\label{sec:new-lines}
\subsubsection{Keeping in Context}
\subsubsection{Blank Lines}
\subsubsection{Rhyming Lines}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

\section{Rephrase for Poetic Features}
\label{sec:rephrase}

\subsection{Rhyme}


\subsection{Rhythm}

\subsubsection{Syllabic}
\paragraph{Extending}
\paragraph{Reducing}

\subsubsection{Accentual}


\subsection{Sound Patterns}

%~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


% ------------------------------------------------------------------------

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: 
